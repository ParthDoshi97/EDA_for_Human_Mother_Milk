library(gridExtra)
library(Boruta)
library(ggbiplot)
library(ggcorrplot)
library(moments)
library(skimr)
# Set Working Directory
setwd("C:/Users/Parth Doshi/Dropbox/Nutrishield_Study_II_Project (ParthD thesis)/R-script/EDA_for_Human_Mother_Milk")
#load Data
SCFA.Data <- read.csv("C:/Users/Parth Doshi/Dropbox/Nutrishield_Study_II_Project (ParthD thesis)/Study2-Data/NUTRISHIELD_Study_II_SCFA_Urine.csv",
sep = ";", skip = 3)
str(SCFA.Data)
# Data cleaning: Remove the rest of clinical data
SCFA.Data <- SCFA.Data %>%
select(-c(1:7),-c(9:13,186), ) %>%
# Transpose the data frame
t() %>%
# Convert the transposed data frame to a regular data frame
as.data.frame() %>%
# Set the first row as column names
row_to_names(1) %>%
# Convert all columns to numeric except the "Class" column
mutate_if(names(.) != "Class", as.numeric) %>%
# Set the "Sample" column as a separate column named "Sample"
rownames_to_column(var = "Sample") %>%
# Remove the "(umol/gcreat)" from column names
rename_with(~str_remove(., "\\s*\\(umol\\/gcreat\\)"), everything())
# Print the summary of the cleaned SCFA.Data
skimmes <- skim_to_list(SCFA.Data)
skimmes
# Write the cleaned data to a CSV file
# write.csv(SCFA.Data,"C:/Users/Parth Doshi/Dropbox/Nutrishield_Study_II_Project (ParthD #thesis)/Study2-clean-Data/NUTRISHIELD_Study_II_SCFA_Urine.csv", row.names = FALSE)
# Drop the Acetic Acid column which has a large number of missing values
SCFA.Data <- SCFA.Data %>%
select(-Acetic)
# Data Distribution
# Convert the data from wide to long format using the gather() function
SCFA.Data.long <- gather(SCFA.Data[3:13])
# Create a boxplot using ggplot
SCFA.Data.boxplot <- ggplot(SCFA.Data.long, aes(x = value, y = key, fill = key)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1) +
labs(title = "Raw SCFA Data Boxplot")
# Print the boxplot
print(SCFA.Data.boxplot)
# Calculate the skewness of the columns in SCFA.Data
skewness(SCFA.Data[3:13])
# Apply scaling to the data
# Convert the columns to log10 scale
SCFA.Data.Scaled <- as.data.frame(log10(SCFA.Data[3:13]))
# Replacing the value Infinite value  with 0
for (col in names(SCFA.Data.Scaled)) {
SCFA.Data.Scaled[[col]][!is.finite(SCFA.Data.Scaled[[col]])] <- 0
}
# Summary statistics
skimmes_normal <- skim_to_list(SCFA.Data.Scaled)
skimmes_normal
# Calculate the skewness of the scaled data
skewness(SCFA.Data.Scaled)
# Combine the scaled data with the first two columns from the original data
SCFA.Data.Scaled <- as.data.frame(cbind(SCFA.Data[1:2], SCFA.Data.Scaled))
# Convert the data from wide to long format using the gather() function
SCFA.Data.Scaled.long <- gather(SCFA.Data.Scaled[3:13])
# Create a boxplot of the scaled data using ggplot
SCFA.Data.Scaled.boxplot <- ggplot(SCFA.Data.Scaled.long, aes(x = value, y = key, fill = key)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1) +
labs(title = "Scaled SCFA Data Boxplot")
# Print the boxplot
print(SCFA.Data.Scaled.boxplot)
# Box plot of data distribution of each group (Mother, PI, TI)
# Convert the data to long format using gather()
SCFA.Data.Scaled %>%
gather(key = "feature", value = "value", -Sample, -Class) %>%
# Create a boxplot using ggplot
ggplot(aes(x = Class, y = value, fill = Class)) +
geom_boxplot() +
# Create separate plots for each feature using facet_wrap()
facet_wrap(~ feature, scales = "free") +
# Set the x-axis label as "Group" and y-axis label as "Value"
labs(x = "Group", y = "Value")
# Remove the features which as large no of outliers seen in above box plot
SCFA.Data.Scaled <- SCFA.Data.Scaled %>%
select(-Isovaleric,-Valeric)
# Perform PCA on the scaled data
SCFA.Data.Scaled.pca <- prcomp(SCFA.Data.Scaled[3:11], scale = TRUE, center = TRUE)
# Visualization of PCA
# Plot the individuals (samples) in the PCA space
fviz_pca_ind(SCFA.Data.Scaled.pca,
geom = "point",
habillage = SCFA.Data.Scaled$Class,
palette = c("blue", "red", "green"),
addEllipses = TRUE,
ellipse.type = "confidence",
ggtheme = theme_bw(),
title = "PCA plot for SCFA biomarkers")
# Scree plot to visualize the explained variance by each principal component
fviz_eig(SCFA.Data.Scaled.pca,
addlabels = TRUE,
ylim = c(0, 70),
main = "Scree Plot SCFA Data")
# Graph showing the contribution of variables to each principal component
fviz_pca_var(SCFA.Data.Scaled.pca, col.var = "red")
# Calculate p-values for each correlation coefficient
p.mat <- cor_pmat(SCFA.Data.Scaled[3:11], method = "pearson")
# Calculate correlation matrix using Pearson correlation
correlationMatrix <- cor(SCFA.Data.Scaled[3:12], method = "pearson")
# Calculate p-values for each correlation coefficient
p.mat <- cor_pmat(SCFA.Data.Scaled[3:11], method = "pearson")
# Calculate correlation matrix using Pearson correlation
correlationMatrix <- cor(SCFA.Data.Scaled[3:11], method = "pearson")
# Visualize the correlation matrix using ggcorrplot
ggcorrplot(
correlationMatrix,
hc.order = TRUE,   # Hierarchical clustering for reordering variables
type = "lower",    # Show only the lower triangle of the correlation matrix
lab = TRUE,        # Show labels for variables
p.mat = p.mat      # Overlay p-values on the plot
)
cov_df <- cov(SCFA.Data.Scaled[sapply(SCFA.Data.Scaled,is.numeric)], method = "pearson")
cov_df_long <- melt(cov_df)
# Create the covariance plot using ggplot2
plot <- ggplot(cov_df_long, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(high = "red", low = "white") +
geom_text(aes(label = round(value, 2)), color = "black", size = 3) +
labs(title = "Covariance Heatmap",
x = "Variable 1",
y = "Variable 2")
print(plot)
View(cov_df)
cov2cor(cov_df)
cov_df <- cov(SCFA.Data.Scaled[sapply(SCFA.Data.Scaled,is.numeric)], method = "pearson")
cov_df <- cov2cor(cov_df)
cov_df_long <- melt(cov_df)
# Create the covariance plot using ggplot2
plot <- ggplot(cov_df_long, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(high = "red", low = "white") +
geom_text(aes(label = round(value, 2)), color = "black", size = 3) +
labs(title = "Covariance Heatmap",
x = "Variable 1",
y = "Variable 2")
print(plot)
cov_df <- cov(SCFA.Data.Scaled[sapply(SCFA.Data.Scaled,is.numeric)], method = "pearson")
cov_df <- cov2cor(cov_df)
cov_df_long <- melt(cov_df)
# Create the covariance plot using ggplot2
plot <- ggplot(cov_df_long, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(high = "red", low = "white") +
geom_text(aes(label = paste0(round(value * 100, 2), "%")), color = "black", size = 3) +
labs(title = "Covariance Heatmap",
x = "Variable 1",
y = "Variable 2")
print(plot)
# Create the covariance plot using ggplot2
plot <- ggplot(cov_df_long, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(high = "red", low = "white") +
geom_text(aes(label = paste0(round(value * 100, 2))), color = "black", size = 3) +
labs(title = "Covariance Heatmap",
x = "Variable 1",
y = "Variable 2")
print(plot)
library(car)
# perform levene's test to see if all group has equal variance
for (vars in continuous.vars) {
formula <- as.formula(paste(vars, "~", categorical.var))
var_test <- leveneTest(formula, data = SCFA.Data.Scaled)
cat("Variable:", vars, "\n")
print(var_test)
cat("\n")
}
SCFA.Data.Scaled$Class <- factor(SCFA.Data.Scaled$Class)
View(SCFA.Data.Scaled)
# perform levene's test to see if all group has equal variance
for (vars in continuous.vars) {
formula <- as.formula(paste(vars, "~", categorical.var))
var_test <- leveneTest(formula, data = SCFA.Data.Scaled)
cat("Variable:", vars, "\n")
print(var_test)
cat("\n")
}
# Perform Shapiro-Wilk test for each numeric variable to check normalitty
for (i in 3:ncol(SCFA.Data.Scaled)) {
result <- shapiro.test(SCFA.Data.Scaled[, i])
print(results)
}
SCFA.Data.Scaled$Class <- factor(SCFA.Data.Scaled$Class)
# Define the Continuous Variables
continuous.vars <- c("Propionic", "Isobutyric", "Butyric", "`2-Me-butyric`", "Caproic", "Heptanoic", "Valine", "Leucine", "Isoleucine")
categorical.var <- "Class"
# perform levene's test to see if all group has equal variance
for (vars in continuous.vars) {
formula <- as.formula(paste(vars, "~", categorical.var))
var_test <- leveneTest(formula, data = SCFA.Data.Scaled)
cat("Variable:", vars, "\n")
print(var_test)
cat("\n")
}
# Perform Kruskal-Wallis test for each variable
for (vars in continuous.vars) {
formula <- as.formula(paste(vars, "~", categorical.var))
kruskal_model <- kruskal.test(formula, data = SCFA.Data.Scaled)
cat("Variable:", vars, "\n")
print(kruskal_model)
cat("\n")
}
# Perform ANOVA and display summary for each model
for (vars in continuous.vars) {
formula <- as.formula(paste(vars, "~", categorical.var))
aov_model <- aov(formula, data = SCFA.Data.Scaled)
tukey_test <- TukeyHSD(aov_model)
cat("Variable:", vars, "\n")
print(summary(aov_model))
print(tukey_test)
cat("\n")
}
# log 10 transformation
# Perform log10 transformation on columns 3 to 24
Targeted.biomarkers.data.Normal <- as.data.frame(log10(Targeted.biomarkers.data[3:24]))
knitr::opts_chunk$set(dev = "png",
dpi = 300,
echo = TRUE,
cache = TRUE)
# install required library
library(devtools)
#devtools::install_github("sfirke/janitor")
# load Required libraries
library(tidyverse) # meta package of all tidyverse packages
library(janitor)
library(ggplot2)
library(caret)
library(ggcorrplot)
library(FactoMineR)
library(ggfortify)
library(factoextra)
library(reshape2)
library(ggbiplot)
library(stringr)
library(corrplot)
library(moments)
# Set Working Directory
setwd("C:/Users/Parth Doshi/Dropbox/Nutrishield_Study_II_Project (ParthD thesis)/R-script/EDA_for_Human_Mother_Milk")
# load Data set
Targeted.biomarkers.data <- read.csv("C:/Users/Parth Doshi/Dropbox/Nutrishield_Study_II_Project (ParthD thesis)/Study2-Data/NUTRISHIELD_Study_II_QTrap_Targeted_Urine.csv", sep = ";", skip = 3)
str(Targeted.biomarkers.data)
# Data cleaning for Targeted Biomarkers Data
# Select the columns containing "IU" or "MU" in their names
Targeted.biomarkers.data <- Targeted.biomarkers.data %>%
select(Sample, contains(c("IU", "MU"))) %>%
# Transpose the data to convert it from wide to long format
t() %>%
as.data.frame() %>%
# Set the first row as column names
row_to_names(1) %>%
# Convert variables to double (numeric) except for the "Class" column
mutate_if(names(.) != "Class", as.double) %>%
# Rename the rownames column as "Samples"
rownames_to_column(var = "Samples")
# Remove the "(umol/g creat)" part from the column names using regex
colnames(Targeted.biomarkers.data) <- gsub("\\s*\\(umol\\/g creat\\)", "", colnames(Targeted.biomarkers.data))
# Display the first few rows of the cleaned data
skimmed_target <-  skim_to_list(Targeted.biomarkers.data)
# Save the clean data to a CSV file
write.csv(Targeted.biomarkers.data, "C:/Users/Parth Doshi/Dropbox/Nutrishield_Study_II_Project (ParthD thesis)/Study2-clean-Data/NUTRISHIELD_Study_II_QTrap_Targeted.csv", row.names = FALSE)
# Function to check if features has Constant value or very few unique values
check.constant.or.few.unique <- function(data) {
result <- vector("character", length = ncol(data))
for (i in 1:ncol(data)) {
column <- data[[i]]
if (length(unique(column)) == 1) {
result[i] <- "Constant value"
} else if (length(unique(column)) <= 50) {
result[i] <- "Few unique values"
} else {
result[i] <- "No pattern"
}
}
pattern_columns <- names(data)[result != "No pattern"]
return(pattern_columns)
}
results <- check.constant.or.few.unique(Targeted.biomarkers.data)
print(results)
Targeted.biomarkers.data <- Targeted.biomarkers.data %>%
select(-`3-IPA`,-Daidzein,-Equol,-Glycitein,-Genistein)
# Data Distribution
# Gather columns 3 to 14 into a long format
Targeted.biomarkers.data.long.A <- gather(Targeted.biomarkers.data[3:14])
# Gather columns 15 to 24 into a long format
Targeted.biomarkers.data.long.B <- gather(Targeted.biomarkers.data[15:24])
# Generate a box plot for Targeted.biomarkers.data.long.A
ggplot(Targeted.biomarkers.data.long.A, aes(x = value, y = key, fill = key)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1) +
labs(title = "Data Distribution box plot before normalization")
# Generate a box plot for Targeted.biomarkers.data.long.B
ggplot(Targeted.biomarkers.data.long.B, aes(x = value, y = key, fill = key)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1) +
labs(title = "Data Distribution box plot before normalization")
# Calculate skewness for columns 3 to 24
skewness(Targeted.biomarkers.data[3:24])
# log 10 transformation
# Perform log10 transformation on columns 3 to 24
Targeted.biomarkers.data.Normal <- as.data.frame(log10(Targeted.biomarkers.data[3:24]))
# Replace infinite values with 0
for (col in names(Targeted.biomarkers.data.Normal)) {
Targeted.biomarkers.data.Normal[[col]][!is.finite(Targeted.biomarkers.data.Normal[[col]])] <- 0
}
# Combine the transformed data with the first two columns from the original data
Targeted.biomarkers.data.Normal <- cbind(Targeted.biomarkers.data[1:2], Targeted.biomarkers.data.Normal)
# Generate summary statistics for the transformed data
skimmed_target_normal <- skim_to_list(Targeted.biomarkers.data.Normal)
# Calculate skewness after the transformation
skewness(Targeted.biomarkers.data.Normal[3:24])
# Box plot after the transformation
Targeted.biomarkers.data.Normal.long.A <- gather(Targeted.biomarkers.data.Normal[3:14])
Targeted.biomarkers.data.Normal.long.B <- gather(Targeted.biomarkers.data.Normal[15:24])
# Generate a box plot for Targeted.biomarkers.data.Normal.long.A
ggplot(Targeted.biomarkers.data.Normal.long.A, aes(x = value, y = key, fill = key)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1) +
labs(title = "Data Distribution box plot before normalization") +
xlim(-1, 5)
# Generate a box plot for Targeted.biomarkers.data.Normal.long.B
ggplot(Targeted.biomarkers.data.Normal.long.B, aes(x = value, y = key, fill = key)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1) +
labs(title = "Data Distribution box plot after normalization") +
xlim(-1, 5)
# Box plot of data distribution of each group (Mother , PI , TI)
Targeted.biomarkers.data.Normal %>%
gather(key = "feature", value = "value", -Samples, -Class) %>%
ggplot(aes(x = Class, y = value, fill = Class)) +
geom_boxplot() +
facet_wrap(~ feature, scales = "free") +
labs(x = "Group", y = "Value")
# Removing the variable which has large  no of outliers
Targeted.biomarkers.data.Normal <- Targeted.biomarkers.data.Normal %>%
select(-Quercetin, -Kaempferol)
# Principle component Analysis
Targeted.biomarkers.Data.Normalise.pca <- prcomp(Targeted.biomarkers.data.Normal[3:22], scale. = TRUE, center = TRUE)
#Visualization of PCA
fviz_pca_ind(Targeted.biomarkers.Data.Normalise.pca,
geom = "point",
habillage = Targeted.biomarkers.data.Normal$Class,
palette = c("blue", "red","yellow"),
addEllipses = TRUE,
ellipse.type="confidence",
ggtheme = theme_bw(),
title = "PCA plot for Qtrap targeted biomarkrs")
#Scree plot
fviz_eig(Targeted.biomarkers.Data.Normalise.pca,
addlabels = TRUE,
ylim = c(0, 70),
main="Scree Plot Qtrap targeted Biomarkers")
#Graph for variable
fviz_pca_var(Targeted.biomarkers.Data.Normalise.pca, col.var = "red")
# biplot
biplot = ggbiplot(pcobj = Targeted.biomarkers.Data.Normalise.pca,
choices = c(1,2),
scale = 0,
varname.size = 2.5,
varname.abbrev = FALSE,  # Abbreviate variable names (TR
var.axes = TRUE,      # Remove variable vectors (TRUE)
circle = FALSE,        # Add unit variance circle (TRUE
ellipse = FALSE, groups = Targeted.biomarkers.data.Normal$Class) # Adding ellipses
print(biplot)
# Calculate p-values for each correlation coefficient
p.mat <- cor_pmat(Targeted.biomarkers.data.Normal[3:22], method = "pearson")
# Calculate correlation matrix using Pearson correlation
correlationMatrix <- cor(Targeted.biomarkers.data.Normal[3:22], method = "pearson")
# Visualize the correlation matrix using ggcorrplot
ggcorrplot(
correlationMatrix,
hc.order = TRUE,   # Hierarchical clustering for reordering variables
type = "lower",    # Show only the lower triangle of the correlation matrix
lab = FALSE,        # Show labels for variables
p.mat = p.mat      # Overlay p-values on the plot
)
cov_df <- cov(Targeted.biomarkers.data.Normal[sapply(Targeted.biomarkers.data.Normal,is.numeric)], method = "pearson")
cov_df <- cov2cor(cov_df)
cov_df_long <- melt(cov_df)
# Create the covariance plot using ggplot2
plot <- ggplot(cov_df_long, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(high = "red", low = "white") +
geom_text(aes(label = paste0(round(value * 100, 2))), color = "black", size = 3) +
labs(title = "Covariance Heatmap",
x = "Variable 1",
y = "Variable 2")
print(plot)
# Define the Continuous Variables
continuous.vars <- c("Phenylpropionylglycine", "Taurine", "Citrulline", "Galactitol", "Isovalerylglycine", "Isobutyrylglycine", "TMAO", "Anserine", "`1-Methylhistidine`", "`3-Methylhistidine`", "`L-Kynurenine`", "`L-Tyrosine`", "`O-DMA`", "Phloretin", "Hesperetin", "`Proline betaine`", "`Ferullic Acid Sulfate`", "`Hippuric Acid`", "`3-IAA`")
categorical.var <- "Class"
# Perform Bartlett's test for each continuous variable
for (vars in continuous.vars) {
formula <- as.formula(paste(vars, "~", categorical.var))
bartlett_test <- bartlett.test(formula, data = Targeted.biomarkers.data.Normal)
cat("Variable:", vars, "\n")
print(bartlett_test)
cat("\n")
}
# Perform ANOVA and display summary for each model
for (vars in continuous.vars) {
formula <- as.formula(paste(vars, "~", categorical.var))
aov_model <- aov(formula, data = Targeted.biomarkers.data.Normal)
tukey_test <- TukeyHSD(aov_model)
cat("Variable:", vars, "\n")
print(summary(aov_model))
print(tukey_test)
cat("\n")
}
# perform regression
for (Vars in continuous.vars) {
formula <- as.formula(paste(Vars, "~", categorical.var))
Lm.model <-lm(formula, data = Targeted.biomarkers.data.Normal)
cat("Variable:",Vars, "\n")
print(summary(Lm.model))
cat("\n")
}
Targeted.biomarkers.data.Normal$Class <- factor(Targeted.biomarkers.data.Normal$Class, labels = c("Mother","TI","PI"))
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(Targeted.biomarkers.data.Normal[,3:22], Targeted.biomarkers.data.Normal[,2], sizes=c(1:22), rfeControl=control)
# summarize the results
print(results)
# list the chosen features
predictors(results)
library(Boruta)
# Decide if a variable is important or not using Boruta
boruta_output <- Boruta(Class ~ ., data=na.omit(Targeted.biomarkers.data.Normal), doTrace=2)  # perform Boruta search
boruta_signif <- names(boruta_output$finalDecision[boruta_output$finalDecision %in% c("Confirmed", "Tentative")])  # collect Confirmed and Tentative variables
# plot variable
plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
# Calculate p-values for each correlation coefficient
p.mat <- cor_pmat(Targeted.biomarkers.data.Normal[3:22], method = "pearson")
# Calculate correlation matrix using Pearson correlation
correlationMatrix <- cor(Targeted.biomarkers.data.Normal[3:22], method = "pearson")
# Visualize the correlation matrix using ggcorrplot
ggcorrplot(
correlationMatrix,
hc.order = TRUE,   # Hierarchical clustering for reordering variables
type = "lower",    # Show only the lower triangle of the correlation matrix
lab = FALSE,        # Show labels for variables
p.mat = p.mat      # Overlay p-values on the plot
)
# Calculate the covariance matrix using Pearson correlation
cov_df <- cov(Targeted.biomarkers.data.Normal[sapply(Targeted.biomarkers.data.Normal, is.numeric)], method = "pearson")
# Convert covariance matrix to correlation matrix
#cov_df <- cov2cor(cov_df)
# Reshape the correlation matrix to long format
cov_df_long <- melt(cov_df)
# Create the covariance plot using ggplot2
plot <- ggplot(cov_df_long, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(high = "red", low = "white") +
geom_text(aes(label = paste0(round(value * 100, 2))), color = "black", size = 3) +
labs(title = "Covariance Heatmap",
x = "Variable 1",
y = "Variable 2")
# Print the covariance plot
print(plot)
# Calculate p-values for each correlation coefficient
p.mat <- cor_pmat(Targeted.biomarkers.data.Normal[3:22], method = "pearson")
# Calculate correlation matrix using Pearson correlation
correlationMatrix <- cor(Targeted.biomarkers.data.Normal[3:22], method = "pearson")
# Visualize the correlation matrix using ggcorrplot
ggcorrplot(
correlationMatrix,
hc.order = TRUE,   # Hierarchical clustering for reordering variables
type = "lower",    # Show only the lower triangle of the correlation matrix
lab = FALSE,        # Show labels for variables
p.mat = p.mat      # Overlay p-values on the plot
)
# Calculate the covariance matrix using Pearson correlation
cov_df <- cov(Targeted.biomarkers.data.Normal[sapply(Targeted.biomarkers.data.Normal, is.numeric)], method = "pearson")
# Convert covariance matrix to correlation matrix
cov_df <- cov2cor(cov_df)
# Reshape the correlation matrix to long format
cov_df_long <- melt(cov_df)
# Create the covariance plot using ggplot2
plot <- ggplot(cov_df_long, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(high = "red", low = "white") +
geom_text(aes(label = paste0(round(value * 100, 2))), color = "black", size = 3) +
labs(title = "Covariance Heatmap",
x = "Variable 1",
y = "Variable 2")
# Print the covariance plot
print(plot)
# Perform Shapiro-Wilk test for each numeric variable to check normality
for (i in 3:ncol(SCFA.Data.Scaled)) {
result <- shapiro.test(SCFA.Data.Scaled[, i])
print(result)
}
# install required library
library(devtools)
#devtools::install_github("sfirke/janitor")
# load Required libraries
library(tidyverse) # meta package of all tidyverse packages
library(janitor)
library(ggplot2)
library(caret)
library(ggcorrplot)
library(FactoMineR)
library(ggfortify)
library(factoextra)
library(reshape2)
library(ggbiplot)
library(stringr)
library(corrplot)
library(moments)
library(skimr)
library(car)
